\documentclass[final,1p,times]{elsarticle}

\usepackage{amssymb}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{color,array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphics}
\usepackage{multirow}
\usepackage{bm}
\usepackage{threeparttable}
\usepackage{booktabs}
\usepackage{subfloat}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}  
\renewcommand{\algorithmicensure}{\textbf{Output:}}

%\journal{Expert Systems With Applications}

\bibliographystyle{model5-names}\biboptions{authoryear}

\begin{document}
	
\begin{frontmatter}
		
\title{Time-controlled incentive federated crowdsourcing}
		

\author[mymainaddress]{Xiaoqian Jiang }
\ead{220224926@seu.edu.cn}
		
\author[mymainaddress]{Jing Zhang
\corref{mycorrespondingauthor}}
\ead{jingz@seu.edu.cn}
		
%\author[thirdaddress]{}
%\ead{}
		
\cortext[mycorrespondingauthor]{Corresponding author}
\address[mymainaddress]{School of Cyber Science and Engineering, Southeast University, No. 2 SEU Road, Nanjing 211189, China}
%\address[thirdaddress]{}
		
\begin{abstract}
			
\end{abstract}
\begin{keyword}
	
\end{keyword}
\end{frontmatter}

\section{Introduction}
Crowdsourcing provides a feasible way to introduce human intelligence to solve notoriously difficult tasks that cannot be solved by computers alone \citep{Vaughan2017MakingBU}. One of the most widespread applications of crowdsourcing is to collect data from massive Internet workers. The collected data including annotations, locations, content, and so on could be further utilized in downstream AI tasks such as building CV \citep{Kovashka2016CrowdsourcingIC}, NLP \citep{Wang2013PerspectivesOC}, recommendation \citep{Lin2023CompetitiveGI} models. Commercial crowdsourcing platforms such as MTurk, Appen, etc., have provided effective interaction modes between task publishers and workers to facilitate the execution of crowdsourced tasks. It is worth noting that while crowdsourcing provides convenience, it may also expose workers' privacy, which will reduce workers' willingness to participate in tasks. Prior research has shown that sensitive private information such as behavior traits, vocal prints, face images, and locations could be revealed along with the submitted data \citep{xia2020privacy,Tong2020FederatedLI}. Thus, privacy issues are attracting more and more attention in crowdsourcing task design. Some traditional approaches can achieve privacy protection by adding perturbation (e.g., implemented as differential privacy \citep{luo2016incentive,wang2022pps}) or noises \citep{to2018ppo,huang2020traffic}. Notwithstanding, these methods undermine the quality of crowdsourcing since the data uploaded by the workers are blurred.

Crowdsourcing platforms are the hubs for collecting data uploaded by workers. Thus, they are key parts of privacy security, where privacy leaks will affect massive crowdsourcing workers. In current crowdsourcing applications, there is a large class of tasks that collect data (usually annotations) from workers and use them in subsequent machine learning processes \citep{Sheng2019MachineLW}. With the increasing computation power of end devices and the fast growth of broadband networks, the model building can be directly performed on the end devices instead of being processed on the platform. That is, we can introduce federated learning (FL) \citep{mcmahan2017communication} to perform learning tasks. FL allows multiple distributed clients to collaborate on training shared models by iteratively aggregating model updates without exposing the raw data, which realizes privacy-preserving model training with little performance loss \citep{Yang2019FederatedML,Gao2022ASO}. Currently, FL has been fused with crowdsourcing and performs well in some situations \citep{Pandey2019ACF,Tong2020FederatedLI,zhang2021enabling}.

Although FL can effectively mitigate privacy breaches in crowdsourcing it also requires clients (i.e., workers in crowdsourcing) to contribute their data, computing, and communications resources, involving considerable costs. On the other hand, processing data locally on the client side indeed protects privacy. However, malicious attackers and the curious server still exist, who always struggle to probe the privacy lying the training samples from intermediate model parameters and gradients \citep{lyu2020threats,Song2020AnalyzingUP}. Such anxiety toward privacy security exacerbates participant inertia in FL \citep{mothukuri2021survey}. In addition, clients in FL have absolute control over their own devices, bandwidth, and data. That is, only the owners of clients can decide when, where, and how to participate in FL \citep{Liu2021FromDM}. Therefore, the incentive mechanism is very important for clients to participate in FL efficiently \citep{zhan2021incentive}. Unless clients can obtain enough compensation, they are unwilling to take those risks and contribute their resources. Sufficient incentives will encourage clients to respond optimally and eventually improve the performance of learned models.

Current incentive mechanisms in FL are usually designed around the driving factors of clients’ contribution, reputation, and resource allocation \citep{zhan2020learning,zhan2021survey}. Those incentive mechanisms designed for FL, targeting addressing the problems of how to accurately measure the contribution of each client and how to effectively attract and retain more clients, do not work well in crowdsourcing scenarios. The reasons are as follows: i) In federated crowdsourcing, clients (workers) usually have the right to choose the human-intelligence tasks suitable for them. Thus, the incentive mechanism also needs to mobilize workers' interest and enthusiasm for crowdsourcing tasks (e.g., encouraging them to contribute more fresh data). ii) Due to the heterogeneity of clients' objective environments (e.g., computation ability of devices, communication bandwidth, and data resources) and subjective environments (e.g., expertise, dedication, and intention of workers), time control should be considered in federated crowdsourcing. On the one hand, the process of federated crowdsourcing is not necessarily as fast as possible. Platforms need time to assess the quality of submitted data to prevent malicious workers from submitting low-quality data for quick rewards. On the other hand, the server (task publisher) must efficiently respond to delays in receiving data due to device and network failures as well as worker disruptions on client ends rather than waiting passively. iii) In federal crowdsourcing, platforms need to recruit and retain high-quality workers. Workers (clients) expect to be paid fairly and as high as possible. Task publishers (servers) expect to obtain as many high-quality outcomes as possible within their budget. Thus, the incentive mechanism of federated crowdsourcing must make a trade-off among these factors.

To address the above challenges, this paper puts forward \underline{Ti}me-controlled incentive \underline{Fed}erated \underline{Crowd}sourcing (TiFedCrowd), which inspires clients to complete data collection and local model training within the given time limit to optimize the global learning model. TiFedCrowd models the federated crowdsourcing process as a two-stage Stackelberg game \citep{li2017review} with a time limit. In the second stage (rewarding clients), TiFedCrowd allots rewards to clients based on their local model accuracies. Here, only the clients that upload models within the given time will be accepted and rewarded. Clients will adjust their model accuracies in the next round according to the costs of completing federated crowdsourcing tasks (mainly including the computing and communication costs) and the rewards obtained from the server. Through this adjustment, clients will be more proactive in taking on crowdsourcing tasks. In the first stage (maximizing the net utility of the server), TiFedCrowd sets a time interval on the server side to ensure the quality and efficiency of the server-side trained global model while maximizing the server-side net utility. The net utility is defined as the profit obtained by training the global model minus the total cost of incentivizing clients. In addition, only the models uploaded by the clients within the given time interval will be accepted and rewarded. Finally, we derive the Nash equilibrium in the Stackelberg game, which describes the steady state of the federated crowdsourcing process. The main contributions of the paper are as follows: 

\begin{itemize}
	\item We propose a novel time-controlled incentive federated crowdsourcing (TiFedCrowd), which encourages more workers to complete crowdsourcing tasks with high quality and efficiency as well as protects the privacy of participants. A time interval is set to preliminarily screen the quality of submitted data. The upper bound of the interval enables the publisher (server-side) to specify the fresh level of the data, which is applicable to both instant and non-instant crowdsourcing.
	\item The Nash equilibrium of the Stackelberg game is derived. Furthermore, we prove that the Nash equilibrium of the proposed method can reach a  global maximization of the server and the client utilities.
	\item TiFedCrowd allocates rewards according to contributions, which has strong interpretability. It is conducive to attracting and retaining high-quality crowdsourcing workers, thus maintaining the fairness and accountability of the federated crowdsourcing market.
\end{itemize}

The remainder of the paper is organized as follows: Section~\ref{sec:rw} briefly reviews the related studies.  Section~\ref{sec:mtd} presents the details of the proposed method.  Section~\ref{sec:exp} shows the experimental results and discusses them. Section~\ref{sec:con} concludes the paper with future work.

\section{Related Work}\label{sec:rw}
The research in this paper is divided into two aspects: one is privacy protection in crowdsourcing, and the other is incentive mechanism in FL.

Since crowdsourcing needs to collect data from workers, it is inevitable that there will be some crowdsourcing tasks involving workers' sensitive information, so workers involved in the crowdsourcing tasks will face the risk of privacy disclosure \citep{wu2019bptm,zhang2020decentralized}. Differential privacy \citep{dwork2006differential} has been widely favored in the research field of Internet privacy protection since it was proposed. Nevertheless, differential privacy works by injecting different levels of noise into the model, undoubtedly at the cost of model accuracy \citep{bagdasaryan2019differential}. In addition, there are also techniques to protect the privacy of crowdsourcing workers that introduce various cryptographic algorithms. For example, \cite{shu2018privacy} proposed a privacy-preserving task recommendation scheme for crowdsourcing, which exploits polynomial functions to express multiple keywords of task requirements and worker interests, and then designs a key derivation method based on matrix decomposition. \cite{joshi2020salt} used SALT cryptography in the proposed solution to ensure privacy. \cite{zhang2019privacy} proposed a privacy-preserving traffic monitoring scheme through both adopting a homomorphic Paillier cryptosystem and super-increasing sequence. However, These encryption algorithms are complex, expensive, and cannot resist inference attacks \citep{lin2020secbcs,wang2019towards}.

To alleviate the above defects, FL provides a secure way to work together so that participants can share and leverage data without exposing their privacy. Mean teacher semisupervised FL \citep{zhang2021toward} trains a deep neural network ensemble under a novel semisupervised FL framework, achieving highly accurate and privacy-protected crowdsourcing. \cite{li2020crowdsf} proposed a crowdsourcing framework named CrowdSFL, which combines blockchain with FL to help users implement crowdsourcing with less overhead and higher security. \cite{zhao2021crowdsensing} proposed a privacy-preserving mobile crowdsensing (MCS) system, which integrates FL into MCS and allows participants to locally process sensing data via FL. Nevertheless, These approaches to privacy protection in crowdsourcing by introducing the FL framework are all based on the ideal condition that participants are fully willing to make any contribution.

An incentive mechanism is necessary to ensure the quality and efficiency of FL. Participating in FL consumes computing resources on clients, occupies network bandwidth on clients, and even shortens the battery life of client devices. Clients are not willing to make sacrifices to participate in FL without any return. Accordingly, there is a growing body of research on the incentive mechanism of FL. \cite{zhan2020learn} designed a deep reinforcement learning-based incentive mechanism to determine the optimal pricing strategy for the parameter server and the optimal training strategies for edge nodes. \cite{le2021incentive} formulated the incentive mechanism between the base station and mobile users as an auction game and further proposed the primal-dual greedy auction mechanism to decide winners in the auction and maximize social welfare. \cite{zhang2021incentive} proposed an incentive mechanism of FL based on reputation and reverse auction theory, which selects and rewards participants by combining the reputation and bids of the participants under a limited budget. \cite{9317806} modelled each data owner's contribution and the three categories of computing, communication, and privacy costs based on a multi-dimensional contract approach. \cite{pandey2019incentivize} introduced the crowdsourcing framework into FL and developed a two-stage Starkelberg game to analyze and solve the interests maximization of the client and central server respectively. Exploiting the non-trivial dependence of the training loss on clients’ hidden efforts and private local models, \cite{zhao2023truthful} devised Labeling and Computation Effort and local Model Elicitation mechanisms which incentivize strategic clients to make truthful efforts as desired by the server in local data labeling and local model computation.

Unfortunately, none of these incentive Mechanisms for FL are designed to work in a federated crowdsourcing program that needs to collect data samples manually. Moreover, they all ignore the impact of time on the effectiveness of federated crowdsourcing and fail to respond to the instability of participants and networks. The eFedCrowd proposed in this paper sets a time threshold to assign the data freshness level and task completion time to the determination of task publication. Furthermore, the contribution is measured against the accuracy of the client's local training model, and the rewards are distributed fairly in an economical manner, so as to motivate workers to complete tasks efficiently and with high quality.

\section{Methodology} \label{sec:mtd}
\section{Experiments} \label{sec:exp}
\section{Conclusion} \label{sec:con}

\bibliography{ref,reference1}
\end{document}